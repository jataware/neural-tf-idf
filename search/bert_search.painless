/**
* dot product of two vectors
*
* @param a the first vector (a 1D array of floats)
* @param b the second vector (a 1D array of floats)
* @return the dot product of the two vectors
*/
float dot(float[] a, float[] b) {
    float sum = 0;
    for (int i = 0; i < a.length; i++) {
        sum += a[i] * b[i];
    }
    return sum;
}

/**
* cosine similarity of two vectors
* @param a the first vector (a 1D array of floats)
* @param b the second vector (a 1D array of floats)
* @return the cosine similarity of the two vectors
*/
float cosine_similarity(float[] a, float[] b) {
    return dot(a, b) / (sqrt(dot(a, a)) * sqrt(dot(b, b)));
}




/*
Search pre-process:
- corpus of documents are embedded into elasticsearch, each doc as a 2D array with shape [num_tokens_doc, embedding_dim]
   -> embedding is handled via python script
- query is embedded as [num_tokens_query, embedding_dim]
   -> embedding is handled via python script
Search process:
- look at a document i:
    - tf_i for each token in query -> float[] with shape [num_tokens_query]
    - df_i for each token in query -> float[] with shape [num_tokens_query]
- aggregate df across all documents -> makes df same for all docs i
- calculate tf-idf for each token in query -> float[] with shape [num_tokens_query]
- sum tf-idf for each token to get the score for the document -> float
*/













/**
* neural-tf-idf score between two embedded text matrices.
* @param query The embedded query matrix (a 2D array of floats) with shape [num_tokens_query, embedding_dim]
* @param doc The embedded doc matrix (a 2D array of floats) with shape [num_tokens_doc, embedding_dim]
* @return The score from performing neural-tf-idf on the two matrices
*/
// float score(float[][] query, float[][] doc) {
//     /*
//         # Reference from python:
//         scores = torch.cosine_similarity(encoded_query[None,:,None], self.encoded_corpus[:,None], dim=3)
//         tf = torch.sum(scores, dim=2)
//         idf = torch.max(scores, dim=2).values.sum(dim=0)
//     */
//     // scores = torch.cosine_similarity(query[:, :, None], doc[:,None], dim=2)
//     float[][] scores = new float[query.length][doc.length];
//     for (int i = 0; i < query.length; i++) {
//         for (int j = 0; j < doc.length; j++) {
//             scores[i][j] = cosine_similarity(a[i], b[j]);
//         }
//     }

//     // tf = torch.sum(scores, dim=1)
//     float[] tf = new float[query.length];
//     for (int i = 0; i < query.length; i++) {
//         for (int j = 0; j < doc.length; j++) {
//             tf[i] += scores[i][j];
//         }
//     }

//     // idf = torch.max(scores, dim=1).values.sum(dim=0)
//     float[] idf = new float[query.length];



    
// }


/**
* compute the cosine similarity scores between each pair of embedded vectors in the query and doc matrices
* @param query The embedded query matrix (a 2D array of floats) with shape [num_tokens_query, embedding_dim]
* @param doc The embedded doc matrix (a 2D array of floats) with shape [num_tokens_doc, embedding_dim]
* @return The cosine similarity scores between each pair of embedded vectors in the query and doc matrices with shape [num_tokens_query, num_tokens_doc]
*/
float[][] compute_scores(float[][] query, float[][] doc) {
    float[][] scores = new float[query.length][doc.length];
    for (int i = 0; i < query.length; i++) {
        for (int j = 0; j < doc.length; j++) {
            scores[i][j] = cosine_similarity(query[i], doc[j]);
        }
    }
    return scores;
}


/**
* compute the 

*/
float soft_tf(float[][] scores)
{

}

float soft_df(float[][] scores)
{

}